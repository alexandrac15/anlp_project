{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4737a8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import torchtext\n",
    "from torchtext.data import get_tokenizer\n",
    "import fasttext.util\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43afcd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_en_train_0 = 'data/train/en/En-Subtask1-fold_0.tsv'\n",
    "path_en_train_1 = 'data/train/en/En-Subtask1-fold_1.tsv'\n",
    "path_en_train_2 = 'data/train/en/En-Subtask1-fold_2.tsv'\n",
    "\n",
    "path_en_test    = 'data/test/En-Subtask1-labels.tsv'\n",
    "\n",
    "path_fr_train_0 = 'data/train/fr/Fr-Subtask1-fold_0.tsv'\n",
    "path_fr_train_1 = 'data/train/fr/Fr-Subtask1-fold_1.tsv'\n",
    "path_fr_train_2 = 'data/train/fr/Fr-Subtask1-fold_2.tsv'\n",
    "\n",
    "path_fr_test    = 'data/test/Fr-Subtask1-labels.tsv'\n",
    "\n",
    "path_it_train_0 = 'data/train/it/It-Subtask1-fold_0.tsv'\n",
    "path_it_train_1 = 'data/train/it/It-Subtask1-fold_1.tsv'\n",
    "path_it_train_2 = 'data/train/it/It-Subtask1-fold_2.tsv'\n",
    "\n",
    "path_it_test    = 'data/test/It-Subtask1-labels.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3b44e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Read data:\n",
    "\n",
    "#EN\n",
    "#Train data \n",
    "train_data_en_0 = pd.read_table(path_en_train_0)\n",
    "train_data_en_1 = pd.read_table(path_en_train_1)\n",
    "train_data_en_2 = pd.read_table(path_en_train_2)\n",
    "#Test data\n",
    "test_data_en    = pd.read_table(path_en_test)\n",
    "\n",
    "\n",
    "#FR\n",
    "#Train data \n",
    "train_data_fr_0 = pd.read_table(path_fr_train_0)\n",
    "train_data_fr_1 = pd.read_table(path_fr_train_1)\n",
    "train_data_fr_2 = pd.read_table(path_fr_train_2)\n",
    "#Test data\n",
    "test_data_fr    = pd.read_table(path_fr_test)\n",
    "\n",
    "\n",
    "#IT\n",
    "#Train data \n",
    "train_data_it_0 = pd.read_table(path_it_train_0)\n",
    "train_data_it_1 = pd.read_table(path_it_train_1)\n",
    "train_data_it_2 = pd.read_table(path_it_train_2)\n",
    "#Test data\n",
    "test_data_it    = pd.read_table(path_it_test)\n",
    "\n",
    "#Define sentences and labels arrays:\n",
    "\n",
    "#EN-----------------------------------------------------------\n",
    "#Train data \n",
    "\n",
    "#Senetnces:\n",
    "train_sentences_en_0 = train_data_en_0[['Sentence']].to_numpy()\n",
    "train_sentences_en_1 = train_data_en_1[['Sentence']].to_numpy()\n",
    "train_sentences_en_2 = train_data_en_2[['Sentence']].to_numpy()\n",
    "\n",
    "#Labels\n",
    "train_labels_en_0 = train_data_en_0['Labels'].to_numpy()\n",
    "train_labels_en_1 = train_data_en_1['Labels'].to_numpy()\n",
    "train_labels_en_2 = train_data_en_2['Labels'].to_numpy()\n",
    "\n",
    "#Test data:\n",
    "test_sentences_en = test_data_en[['Sentence']].to_numpy()\n",
    "test_labels_en    = test_data_en['Labels'].to_numpy()\n",
    "\n",
    "\n",
    "#FR-----------------------------------------------------------\n",
    "#Train data \n",
    "\n",
    "#Senetnces:\n",
    "train_sentences_fr_0 = train_data_fr_0[['Sentence']].to_numpy()\n",
    "train_sentences_fr_1 = train_data_fr_1[['Sentence']].to_numpy()\n",
    "train_sentences_fr_2 = train_data_fr_2[['Sentence']].to_numpy()\n",
    "\n",
    "#Labels\n",
    "train_labels_fr_0 = train_data_fr_0['Labels'].to_numpy()\n",
    "train_labels_fr_1 = train_data_fr_1['Labels'].to_numpy()\n",
    "train_labels_fr_2 = train_data_fr_2['Labels'].to_numpy()\n",
    "\n",
    "#Test data:\n",
    "test_sentences_fr = test_data_fr[['Sentence']].to_numpy()\n",
    "test_labels_fr    = test_data_fr['Labels'].to_numpy()\n",
    "\n",
    "\n",
    "#IT-----------------------------------------------------------\n",
    "#Train data \n",
    "\n",
    "#Senetnces:\n",
    "train_sentences_it_0 = train_data_it_0[['Sentence']].to_numpy()\n",
    "train_sentences_it_1 = train_data_it_1[['Sentence']].to_numpy()\n",
    "train_sentences_it_2 = train_data_it_2[['Sentence']].to_numpy()\n",
    "\n",
    "#Labels\n",
    "train_labels_it_0 = train_data_it_0['Labels'].to_numpy()\n",
    "train_labels_it_1 = train_data_it_1['Labels'].to_numpy()\n",
    "train_labels_it_2 = train_data_it_2['Labels'].to_numpy()\n",
    "\n",
    "#Test data:\n",
    "test_sentences_it = test_data_it[['Sentence']].to_numpy()\n",
    "test_labels_it    = test_data_it['Labels'].to_numpy()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c70fbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = get_tokenizer('spacy', language=\"en_core_web_sm\")\n",
    "tokenizer_fr = get_tokenizer('spacy', language=\"fr_core_news_sm\")\n",
    "tokenizer_it = get_tokenizer('spacy', language=\"it_core_news_sm\")\n",
    "\n",
    "\n",
    "def tokenize(data,tokenizer):\n",
    "    tokenised_sentences = []\n",
    "    for row in data:\n",
    "        tokenised_sentences.append(tokenizer(row[0]))\n",
    "    return np.array(tokenised_sentences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7724f528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-bf580b009f5b>:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(tokenised_sentences)\n"
     ]
    }
   ],
   "source": [
    "#EN---------------------------\n",
    "tokenized_train_sentences_en_0 = tokenize(train_sentences_en_0, tokenizer_en)\n",
    "tokenized_train_sentences_en_1 = tokenize(train_sentences_en_1, tokenizer_en)\n",
    "tokenized_train_sentences_en_2 = tokenize(train_sentences_en_2, tokenizer_en)\n",
    "\n",
    "tokenized_test_sentences_en    = tokenize(test_sentences_en,tokenizer_en)\n",
    "\n",
    "#EN---------------------------\n",
    "tokenized_train_sentences_fr_0 = tokenize(train_sentences_fr_0,tokenizer_fr)\n",
    "tokenized_train_sentences_fr_1 = tokenize(train_sentences_fr_1,tokenizer_fr)\n",
    "tokenized_train_sentences_fr_2 = tokenize(train_sentences_fr_2,tokenizer_fr)\n",
    "\n",
    "tokenized_test_sentences_fr    = tokenize(test_sentences_fr, tokenizer_fr)\n",
    "\n",
    "#IT---------------------------\n",
    "tokenized_train_sentences_it_0 = tokenize(train_sentences_it_0, tokenizer_it)\n",
    "tokenized_train_sentences_it_1 = tokenize(train_sentences_it_1, tokenizer_it)\n",
    "tokenized_train_sentences_it_2 = tokenize(train_sentences_it_2, tokenizer_it)\n",
    "\n",
    "tokenized_test_sentences_it    = tokenize(test_sentences_it, tokenizer_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bbc9ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_words_to_indexes(goal,extra) :\n",
    "    sentences  = np.concatenate((goal, extra), axis = 0)\n",
    "    vocabulary = set()\n",
    "    for s in sentences:\n",
    "        vocabulary.update(s)# Add to the vocabulary\n",
    "    #Add indexes to vocab\n",
    "    word_list    =  list(vocabulary)  \n",
    "    word_indexes = list(range(0, len(word_list)))\n",
    "    vocabulary_indexed = dict(zip(word_list,word_indexes))\n",
    "    \n",
    "    new=[]\n",
    "    for s in goal:\n",
    "        ns=[]\n",
    "        for w in s:\n",
    "            ns.append(vocabulary_indexed[w])\n",
    "        new.append(torch.tensor(ns))\n",
    "    return new,len(vocabulary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "72d02518",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_sentences_en_all = np.concatenate((tokenized_train_sentences_en_0, tokenized_train_sentences_en_1,tokenized_train_sentences_en_2),0)\n",
    "\n",
    "X_train_en_0,v_en = convert_words_to_indexes(tokenized_train_sentences_en_0,tokenized_test_sentences_en)\n",
    "X_train_en_1,v_en = convert_words_to_indexes(tokenized_train_sentences_en_1,tokenized_test_sentences_en)\n",
    "X_train_en_2,v_en = convert_words_to_indexes(tokenized_train_sentences_en_2,tokenized_test_sentences_en)\n",
    "\n",
    "X_test_en,v_en = convert_words_to_indexes(tokenized_test_sentences_en,tokenized_train_sentences_en_all)\n",
    "\n",
    "#FR:\n",
    "\n",
    "tokenized_train_sentences_fr_all = np.concatenate((tokenized_train_sentences_fr_0, tokenized_train_sentences_fr_1,tokenized_train_sentences_fr_2),0)\n",
    "\n",
    "X_train_fr_0,v_fr = convert_words_to_indexes(tokenized_train_sentences_fr_0,tokenized_test_sentences_fr)\n",
    "X_train_fr_1,v_fr = convert_words_to_indexes(tokenized_train_sentences_fr_1,tokenized_test_sentences_fr)\n",
    "X_train_fr_2,v_fr = convert_words_to_indexes(tokenized_train_sentences_fr_2,tokenized_test_sentences_fr)\n",
    "\n",
    "X_test_fr, v_fr = convert_words_to_indexes(tokenized_test_sentences_fr,tokenized_train_sentences_fr_all)\n",
    "\n",
    "#FR:\n",
    "\n",
    "tokenized_train_sentences_it_all = np.concatenate((tokenized_train_sentences_it_0, tokenized_train_sentences_it_1,tokenized_train_sentences_it_2),0)\n",
    "\n",
    "X_train_it_0,v_it = convert_words_to_indexes(tokenized_train_sentences_it_0,tokenized_test_sentences_it)\n",
    "X_train_it_1,v_it = convert_words_to_indexes(tokenized_train_sentences_it_1,tokenized_test_sentences_it)\n",
    "X_train_it_2,v_it = convert_words_to_indexes(tokenized_train_sentences_it_2,tokenized_test_sentences_it)\n",
    "\n",
    "X_test_it,v_it = convert_words_to_indexes(tokenized_test_sentences_it,tokenized_train_sentences_it_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "726da8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_en_0   = torch.tensor(train_labels_en_0)\n",
    "Y_train_en_1   = torch.tensor(train_labels_en_1)\n",
    "Y_train_en_2   = torch.tensor(train_labels_en_2)\n",
    "Y_test_en = torch.tensor(test_labels_en)\n",
    "\n",
    "Y_train_fr_0   = torch.tensor(train_labels_fr_0)\n",
    "Y_train_fr_1   = torch.tensor(train_labels_fr_1)\n",
    "Y_train_fr_2   = torch.tensor(train_labels_fr_2)\n",
    "\n",
    "Y_test_fr = torch.tensor(test_labels_fr)\n",
    "\n",
    "Y_train_it_0   = torch.tensor(train_labels_it_0)\n",
    "Y_train_it_1   = torch.tensor(train_labels_it_1)\n",
    "Y_train_it_2   = torch.tensor(train_labels_it_2)\n",
    "\n",
    "Y_test_it = torch.tensor(test_labels_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6fbad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6e21398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self,n_characters, hidden_size, n_layers):\n",
    "       \n",
    "        super(LSTM,self).__init__()\n",
    "        \n",
    "        self.embedding_dim = 100\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = torch.nn.Embedding(n_characters, self.embedding_dim)\n",
    "\n",
    "\n",
    "        \"\"\"LSTM layer\"\"\"\n",
    "        self.lstm_layer = nn.LSTM(self.embedding_dim,hidden_size,n_layers)\n",
    "        \"\"\"Output Layer\"\"\"\n",
    "        self.output_layer = nn.Linear(hidden_size,1)\n",
    "    \n",
    "    def forward(self, input_char, hidden_state, ):\n",
    "       \n",
    "        sig = nn.Sigmoid()\n",
    "        embeddings_output = self.embedding(input_char)\n",
    "       \n",
    "        output, state = self.lstm_layer(embeddings_output.view(-1,1,100), hidden_state ) \n",
    "        output_network = sig(self.output_layer(state[0]).view(1,1))\n",
    "    \n",
    "        \n",
    "        return( output_network, state)\n",
    "\n",
    "    def init_hidden(self):\n",
    "   \n",
    "        return (torch.zeros(self.n_layers, 1,self.hidden_size),\n",
    "        \n",
    "        torch.zeros(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d9cc298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(decoder, decoder_optimizer, inp, target):\n",
    "    hidden, cell = decoder.init_hidden()\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    output, (hidden, cell) = decoder(inp, (hidden, cell))\n",
    "\n",
    "    loss += criterion(output, target.view(1,1).to(torch.float32))   \n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8900a1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, math #Time logging function taken from assignment 3\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dec4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b62a53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X,Y, hidden_size,  n_layers,  lr, n_epochs):\n",
    "\n",
    "    m = LSTM(n_characters, hidden_size, n_layers)\n",
    "    optimizer = torch.optim.SGD(m.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    start = time.time()\n",
    "    all_losses = []\n",
    "    loss_avg = 0\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        \n",
    "        for i in range(len(X)): \n",
    "      \n",
    "            loss = train(m, optimizer, X[i],Y[i])\n",
    "            loss_avg += loss\n",
    "    \n",
    "     \n",
    "        print('[{} ({} {}%) {:.4f}]'.format(time_since(start), epoch, epoch/n_epochs * 100, loss))\n",
    "    return m, all_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "382cfca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(model,X_test,Y_test):\n",
    "    accuracy = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "    \n",
    "    hidden, cell = model.init_hidden()\n",
    "    logits  = []\n",
    "    labels  = []\n",
    "  \n",
    "    for i in range(len(X_test)):\n",
    "        \n",
    "        gg, (hidden,cell) = model(X_test[i],(hidden, cell))\n",
    "        \n",
    "        if(gg[0]>=0.5):\n",
    "            logits.append(1) \n",
    "        else:\n",
    "            logits.append(0)   \n",
    "            \n",
    "        labels.append(Y_test[i])\n",
    "    \n",
    "    correct = 0\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for i in range(len(logits)):\n",
    "        labl = labels[i]\n",
    "        pred = logits[i]\n",
    "        if (labl==pred):\n",
    "            if labl == 1:\n",
    "                tp += 1\n",
    "            else: \n",
    "                tn += 1\n",
    "        else: \n",
    "            if labl == 1:\n",
    "                fn += 1\n",
    "            else: \n",
    "                fp += 1\n",
    "            \n",
    "    accuracy = (tp+tn)/len(labels)\n",
    "    precision = (tp)/(tp+fp)\n",
    "    recall = (tp)/(tp+fn)\n",
    "    f1 = 2*tp/(2*tp+fp+fn)\n",
    "    \n",
    "    return (accuracy,precision,recall,f1)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5423e9eb",
   "metadata": {},
   "source": [
    "# Experiments:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed07789",
   "metadata": {},
   "source": [
    "## ENGLISH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7071415a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: \n",
      "[0m 8s (1 12.5%) 0.1246]\n",
      "[0m 15s (2 25.0%) 0.0754]\n",
      "[0m 24s (3 37.5%) 0.1083]\n",
      "[0m 32s (4 50.0%) 0.0527]\n",
      "[0m 40s (5 62.5%) 0.0132]\n",
      "[0m 48s (6 75.0%) 0.0014]\n",
      "[0m 55s (7 87.5%) 0.0001]\n",
      "[1m 3s (8 100.0%) 0.0000]\n",
      "Computing evaluation metrics:  \n",
      "Accuracy: 0.6245879120879121\n",
      "Precision: 0.5635364177737059\n",
      "Recall: 0.8975631110462571\n",
      "F1: 0.6923683025664116\n"
     ]
    }
   ],
   "source": [
    "#EN FOLD 0 \n",
    "n_epochs = 8\n",
    "criterion = nn.BCELoss()\n",
    "    \n",
    "hidden_size = 256\n",
    "n_layers = 1\n",
    "n_characters = v_en\n",
    "lr = 0.1\n",
    "\n",
    "X= X_train_en_0\n",
    "Y= Y_train_en_0\n",
    "print(\"Training model: \")\n",
    "m, all_losses = create_model(X,Y, hidden_size,  n_layers,  lr, n_epochs)\n",
    "\n",
    "X_test  = X_test_en\n",
    "Y_test = Y_test_en\n",
    "print(\"Computing evaluation metrics:  \")\n",
    "a,p,r,f1 = metrics(m,X_test,Y_test)\n",
    "print(\"Accuracy: \"+ str(a))\n",
    "print(\"Precision: \"+ str(p))\n",
    "print(\"Recall: \"+ str(r))\n",
    "print(\"F1: \"+ str(f1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7fdca323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: \n",
      "[0m 8s (1 16.666666666666664%) 0.0974]\n",
      "[0m 17s (2 33.33333333333333%) 0.0486]\n",
      "[0m 26s (3 50.0%) 0.0477]\n",
      "[0m 35s (4 66.66666666666666%) 0.0068]\n",
      "[0m 43s (5 83.33333333333334%) 0.0014]\n",
      "[0m 52s (6 100.0%) 0.0003]\n",
      "Computing evaluation metrics:  \n",
      "Accuracy: 0.6384615384615384\n",
      "Precision: 0.5785156636031228\n",
      "Recall: 0.8542244272581351\n",
      "F1: 0.6898420928588263\n"
     ]
    }
   ],
   "source": [
    "#EN FOLD 0 \n",
    "n_epochs = 6\n",
    "criterion = nn.BCELoss()\n",
    "    \n",
    "hidden_size = 256\n",
    "n_layers = 1\n",
    "n_characters = v_en\n",
    "lr = 0.1\n",
    "\n",
    "X= X_train_en_0\n",
    "Y= Y_train_en_0\n",
    "print(\"Training model: \")\n",
    "m, all_losses = create_model(X,Y, hidden_size,  n_layers,  lr, n_epochs)\n",
    "\n",
    "X_test  = X_test_en\n",
    "Y_test = Y_test_en\n",
    "print(\"Computing evaluation metrics:  \")\n",
    "a,p,r,f1 = metrics(m,X_test,Y_test)\n",
    "print(\"Accuracy: \"+ str(a))\n",
    "print(\"Precision: \"+ str(p))\n",
    "print(\"Recall: \"+ str(r))\n",
    "print(\"F1: \"+ str(f1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7651e997",
   "metadata": {},
   "source": [
    "## FRENCH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "207c6f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: \n",
      "[0m 10s (1 12.5%) 0.3939]\n",
      "[0m 20s (2 25.0%) 0.1208]\n",
      "[0m 31s (3 37.5%) 0.0515]\n",
      "[0m 41s (4 50.0%) 0.0204]\n",
      "[0m 51s (5 62.5%) 0.0048]\n",
      "[1m 2s (6 75.0%) 0.0030]\n",
      "[1m 12s (7 87.5%) 0.0015]\n",
      "[1m 23s (8 100.0%) 0.0002]\n",
      "Computing evaluation metrics:  \n",
      "Accuracy: 0.5537087912087912\n",
      "Precision: 0.5162590455253274\n",
      "Recall: 0.8224135415146651\n",
      "F1: 0.6343275182892516\n"
     ]
    }
   ],
   "source": [
    "#FR FOLD 0:\n",
    "n_epochs = 8\n",
    "criterion = nn.BCELoss()\n",
    "    \n",
    "hidden_size = 256\n",
    "n_layers = 1\n",
    "n_characters = v_fr\n",
    "lr = 0.1\n",
    "\n",
    "X= X_train_fr_0\n",
    "Y= Y_train_fr_0\n",
    "print(\"Training model: \")\n",
    "m, all_losses = create_model(X,Y, hidden_size,  n_layers,  lr, n_epochs)\n",
    "\n",
    "X_test  = X_test_fr\n",
    "Y_test = Y_test_fr\n",
    "print(\"Computing evaluation metrics:  \")\n",
    "a,p,r,f1 = metrics(m,X_test,Y_test)\n",
    "print(\"Accuracy: \"+ str(a))\n",
    "print(\"Precision: \"+ str(p))\n",
    "print(\"Recall: \"+ str(r))\n",
    "print(\"F1: \"+ str(f1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4a10201b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: \n",
      "[0m 10s (1 12.5%) 0.6091]\n",
      "[0m 20s (2 25.0%) 0.2176]\n",
      "[0m 30s (3 37.5%) 0.0166]\n",
      "[0m 40s (4 50.0%) 0.0032]\n",
      "[0m 50s (5 62.5%) 0.0249]\n",
      "[1m 0s (6 75.0%) 0.0011]\n",
      "[1m 10s (7 87.5%) 0.0007]\n",
      "[1m 20s (8 100.0%) 0.0001]\n",
      "Computing evaluation metrics:  \n",
      "Accuracy: 0.5149725274725274\n",
      "Precision: 0.4910645575032065\n",
      "Recall: 0.8380271413979279\n",
      "F1: 0.6192581410394652\n"
     ]
    }
   ],
   "source": [
    "#FR FOLD 1:\n",
    "n_epochs = 8\n",
    "criterion = nn.BCELoss()\n",
    "    \n",
    "hidden_size = 256\n",
    "n_layers = 1\n",
    "n_characters = v_fr\n",
    "lr = 0.1\n",
    "\n",
    "X= X_train_fr_1[:1900]\n",
    "Y= Y_train_fr_1[:1900]\n",
    "print(\"Training model: \")\n",
    "m, all_losses = create_model(X,Y, hidden_size,  n_layers,  lr, n_epochs)\n",
    "\n",
    "X_test  = X_test_fr\n",
    "Y_test = Y_test_fr\n",
    "print(\"Computing evaluation metrics:  \")\n",
    "a,p,r,f1 = metrics(m,X_test,Y_test)\n",
    "print(\"Accuracy: \"+ str(a))\n",
    "print(\"Precision: \"+ str(p))\n",
    "print(\"Recall: \"+ str(r))\n",
    "print(\"F1: \"+ str(f1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7ac2f97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: \n",
      "[0m 9s (1 12.5%) 0.0926]\n",
      "[0m 19s (2 25.0%) 0.0429]\n",
      "[0m 29s (3 37.5%) 0.0192]\n",
      "[0m 39s (4 50.0%) 0.0158]\n",
      "[0m 49s (5 62.5%) 0.0005]\n",
      "[0m 59s (6 75.0%) 0.0002]\n",
      "[1m 9s (7 87.5%) 0.0019]\n",
      "[1m 19s (8 100.0%) 0.0000]\n",
      "Computing evaluation metrics:  \n",
      "Accuracy: 0.44759615384615387\n",
      "Precision: 0.4449990756147162\n",
      "Recall: 0.7024660732525901\n",
      "F1: 0.5448474902382434\n"
     ]
    }
   ],
   "source": [
    "#FR FOLD 2:\n",
    "n_epochs = 8\n",
    "criterion = nn.BCELoss()\n",
    "    \n",
    "hidden_size = 256\n",
    "n_layers = 1\n",
    "n_characters = v_fr\n",
    "lr = 0.1\n",
    "\n",
    "X= X_train_fr_2[:1900]\n",
    "Y= Y_train_fr_2[:1900]\n",
    "print(\"Training model: \")\n",
    "m, all_losses = create_model(X,Y, hidden_size,  n_layers,  lr, n_epochs)\n",
    "\n",
    "X_test  = X_test_fr\n",
    "Y_test = Y_test_fr\n",
    "print(\"Computing evaluation metrics:  \")\n",
    "a,p,r,f1 = metrics(m,X_test,Y_test)\n",
    "print(\"Accuracy: \"+ str(a))\n",
    "print(\"Precision: \"+ str(p))\n",
    "print(\"Recall: \"+ str(r))\n",
    "print(\"F1: \"+ str(f1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62830404",
   "metadata": {},
   "source": [
    "## ITALIAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eea90fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: \n",
      "[0m 8s (1 12.5%) 0.0265]\n",
      "[0m 17s (2 25.0%) 0.0062]\n",
      "[0m 25s (3 37.5%) 0.0008]\n",
      "[0m 34s (4 50.0%) 0.0002]\n",
      "[0m 42s (5 62.5%) 0.0001]\n",
      "[0m 51s (6 75.0%) 0.0000]\n",
      "[0m 59s (7 87.5%) 0.0000]\n",
      "[1m 7s (8 100.0%) 0.0000]\n",
      "Computing evaluation metrics:  \n",
      "Accuracy: 0.5043269230769231\n",
      "Precision: 0.48359177785791563\n",
      "Recall: 0.7827228950824456\n",
      "F1: 0.5978266926720535\n"
     ]
    }
   ],
   "source": [
    "#FR FOLD 0:\n",
    "n_epochs = 8\n",
    "criterion = nn.BCELoss()\n",
    "    \n",
    "hidden_size = 256\n",
    "n_layers = 1\n",
    "n_characters = v_it\n",
    "lr = 0.1\n",
    "\n",
    "X= X_train_it_0\n",
    "Y= Y_train_it_0\n",
    "print(\"Training model: \")\n",
    "m, all_losses = create_model(X,Y, hidden_size,  n_layers,  lr, n_epochs)\n",
    "\n",
    "X_test  = X_test_it\n",
    "Y_test = Y_test_it\n",
    "print(\"Computing evaluation metrics:  \")\n",
    "a,p,r,f1 = metrics(m,X_test,Y_test)\n",
    "print(\"Accuracy: \"+ str(a))\n",
    "print(\"Precision: \"+ str(p))\n",
    "print(\"Recall: \"+ str(r))\n",
    "print(\"F1: \"+ str(f1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "228fe6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: \n",
      "[0m 8s (1 12.5%) 0.1437]\n",
      "[0m 16s (2 25.0%) 0.2161]\n",
      "[0m 25s (3 37.5%) 0.0092]\n",
      "[0m 33s (4 50.0%) 0.0019]\n",
      "[0m 42s (5 62.5%) 0.0005]\n",
      "[0m 50s (6 75.0%) 0.0001]\n",
      "[0m 58s (7 87.5%) 0.0001]\n",
      "[1m 7s (8 100.0%) 0.0001]\n",
      "Computing evaluation metrics:  \n",
      "Accuracy: 0.5710164835164835\n",
      "Precision: 0.5327435537814219\n",
      "Recall: 0.7205603385378666\n",
      "F1: 0.6125790844808336\n"
     ]
    }
   ],
   "source": [
    "#FR FOLD 0:\n",
    "n_epochs = 8\n",
    "criterion = nn.BCELoss()\n",
    "    \n",
    "hidden_size = 256\n",
    "n_layers = 1\n",
    "n_characters = v_it\n",
    "lr = 0.1\n",
    "\n",
    "X= X_train_it_1\n",
    "Y= Y_train_it_1\n",
    "print(\"Training model: \")\n",
    "m, all_losses = create_model(X,Y, hidden_size,  n_layers,  lr, n_epochs)\n",
    "\n",
    "X_test  = X_test_it\n",
    "Y_test = Y_test_it\n",
    "print(\"Computing evaluation metrics:  \")\n",
    "a,p,r,f1 = metrics(m,X_test,Y_test)\n",
    "print(\"Accuracy: \"+ str(a))\n",
    "print(\"Precision: \"+ str(p))\n",
    "print(\"Recall: \"+ str(r))\n",
    "print(\"F1: \"+ str(f1))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "66233386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: \n",
      "[0m 8s (1 12.5%) 0.0914]\n",
      "[0m 16s (2 25.0%) 0.0494]\n",
      "[0m 25s (3 37.5%) 0.0094]\n",
      "[0m 33s (4 50.0%) 0.0018]\n",
      "[0m 42s (5 62.5%) 0.0023]\n",
      "[0m 50s (6 75.0%) 0.0005]\n",
      "[0m 59s (7 87.5%) 0.0001]\n",
      "[1m 7s (8 100.0%) 0.0000]\n",
      "Computing evaluation metrics:  \n",
      "Accuracy: 0.654945054945055\n",
      "Precision: 0.5906073516298425\n",
      "Recall: 0.8698380271413979\n",
      "F1: 0.7035288563672843\n"
     ]
    }
   ],
   "source": [
    "#FR FOLD 0:\n",
    "n_epochs = 8\n",
    "criterion = nn.BCELoss()\n",
    "    \n",
    "hidden_size = 256\n",
    "n_layers = 1\n",
    "n_characters = v_it\n",
    "lr = 0.1\n",
    "\n",
    "X= X_train_it_2\n",
    "Y= Y_train_it_2\n",
    "print(\"Training model: \")\n",
    "m, all_losses = create_model(X,Y, hidden_size,  n_layers,  lr, n_epochs)\n",
    "\n",
    "X_test  = X_test_it\n",
    "Y_test = Y_test_it\n",
    "print(\"Computing evaluation metrics:  \")\n",
    "a,p,r,f1 = metrics(m,X_test,Y_test)\n",
    "print(\"Accuracy: \"+ str(a))\n",
    "print(\"Precision: \"+ str(p))\n",
    "print(\"Recall: \"+ str(r))\n",
    "print(\"F1: \"+ str(f1))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
